<table class="configuration table table-bordered">
    <thead>
        <tr>
            <th class="text-left" style="width: 20%">Key</th>
            <th class="text-left" style="width: 15%">Default</th>
            <th class="text-left" style="width: 10%">Type</th>
            <th class="text-left" style="width: 55%">Description</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td><h5>changelog-producer.compaction-interval</h5></td>
            <td style="word-wrap: break-word;">0 ms</td>
            <td>Duration</td>
            <td>When changelog-producer is set to FULL_COMPACTION, full compaction will be constantly triggered after this interval.</td>
        </tr>
        <tr>
            <td><h5>log.system</h5></td>
            <td style="word-wrap: break-word;">"none"</td>
            <td>String</td>
            <td>The log system used to keep changes of the table.<br /><br />Possible values:<br /><ul><li>"none": No log system, the data is written only to file store, and the streaming read will be directly read from the file store.</li></ul><ul><li>"kafka": Kafka log system, the data is double written to file store and kafka, and the streaming read will be read from kafka.</li></ul></td>
        </tr>
        <tr>
            <td><h5>scan.parallelism</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>Integer</td>
            <td>Define a custom parallelism for the scan source. By default, if this option is not defined, the planner will derive the parallelism for each statement individually by also considering the global configuration.</td>
        </tr>
        <tr>
            <td><h5>sink.parallelism</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>Integer</td>
            <td>Defines a custom parallelism for the sink. By default, if this option is not defined, the planner will derive the parallelism for each statement individually by also considering the global configuration.</td>
        </tr>
        <tr>
            <td><h5>sink.partition-shuffle</h5></td>
            <td style="word-wrap: break-word;">false</td>
            <td>Boolean</td>
            <td>The option to enable shuffle data by dynamic partition fields in sink phase for table store.</td>
        </tr>
        <tr>
            <td><h5>streaming-read-atomic</h5></td>
            <td style="word-wrap: break-word;">false</td>
            <td>Boolean</td>
            <td>The option to enable return per iterator instead of per record in streaming read.This can ensure that there will be no checkpoint segmentation in iterator consumption.<br />By default, streaming source checkpoint will be performed in any time, this means 'UPDATE_BEFORE' and 'UPDATE_AFTER' can be split into two checkpoint. Downstream can see intermediate state.</td>
        </tr>
    </tbody>
</table>
